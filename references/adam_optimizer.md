# Adam Optimizer Reference

- **Title:** Adam: A Method for Stochastic Optimization
- **Authors:** Diederik P. Kingma, Jimmy Ba
- **Link:** [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)

## Summary
Adam (Adaptive Moment Estimation) is an optimization algorithm that computes adaptive learning rates for each parameter. It combines the advantages of AdaGrad and RMSProp. This project utilizes the Adam optimizer for training the CNN model due to its efficiency in handling large-scale datasets and sparse gradients.

## BibTeX Citation
```bibtex
@article{kingma2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
```
